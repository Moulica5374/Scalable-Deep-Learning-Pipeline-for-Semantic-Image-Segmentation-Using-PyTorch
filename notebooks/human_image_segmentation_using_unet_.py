# -*- coding: utf-8 -*-
"""Human Image Segmentation using UNet .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fhbNzJnVsU4Sr4rSdY2Xj6d3ThqILrUK

## Set up colab gpu runtime environment
"""

!pip install segmentation-models-pytorch
!pip install -U git+https://github.com/albumentations-team/albumentations
!pip install --upgrade opencv-contrib-python

"""## Download the dataset"""

!git clone https://github.com/parth1620/Human-Segmentation-Dataset-master.git

import torch
import cv2

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from tqdm import tqdm

import helper

"""## Setup configurations"""

csv_file = '/content/Human-Segmentation-Dataset-master/train.csv'
data_dir = '/content/'
DEVICE = 'cuda'
epochs = 25
LR = 0.003
image_size = 320
encoder = 'timm-efficientnet-b0'
weights = 'imagenet'
batch_size =16

df = pd.read_csv(csv_file)
df.head(3)

row = df.iloc[4]
image_path = row.images
mask_path = row.masks

image = cv2.imread(image_path)
image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)

mask= cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE)/255.0

f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))

ax1.set_title('IMAGE')
ax1.imshow(image)

ax2.set_title('GROUND TRUTH')
ax2.imshow(mask,cmap = 'gray')

train_df,valid_df = train_test_split(df,test_size = 0.2,random_state=42)

"""## Augmentation Functions"""

import albumentations as a
def get_train_aug():
  return a.Compose([
      a.Resize(image_size,image_size),
      a.HorizontalFlip(p=0.5),
      a.VerticalFlip(p=0.5)
  ], is_check_shapes=False)

def get_valid_aug():
    return a.Compose([
      a.Resize(image_size,image_size)

  ], is_check_shapes=False)

"""## Create Custom Dataset"""

from torch.utils.data import Dataset
class SegmentationDataset(Dataset):

  def __init__(self, df,augmentations):
    self.df = df
    self.augmentations = augmentations

  def __len__(self):

    return len(self.df)


  def __getitem__(self,idx):
    row =  self.df.iloc[idx]
    image_path = row.images
    mask_path = row.masks

    image =cv2.imread(image_path)
    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)


    mask = cv2.imread(mask_path,cv2.IMREAD_GRAYSCALE)
    mask = np.expand_dims(mask,axis = -1) # Fix 1: Add channel at the end


    if self.augmentations:
      data = self.augmentations(image = image, mask = mask)
      image = data['image']
      mask = data['mask']
    image = np.transpose(image,(2,0,1)).astype(np.float32)
    mask = np.transpose(mask,(2,0,1)).astype(np.float32) # Fix 2: Transpose mask, not image

    image = torch.Tensor(image)/255.0
    mask = torch.round(torch.Tensor(mask)/255.0)


    return image,mask

trainset = SegmentationDataset(train_df,get_train_aug())
validset = SegmentationDataset(valid_df,get_valid_aug())

print(f"Size of Trainset : {len(trainset)}")
print(f"Size of Validset : {len(validset)}")

idx = 42

image,mask = trainset[idx]

def show_image(image,mask,pred_image = None):

    if pred_image == None:

        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,5))

        ax1.set_title('IMAGE')
        ax1.imshow(image.permute(1,2,0).squeeze(),cmap = 'gray')

        ax2.set_title('GROUND TRUTH')
        ax2.imshow(mask.permute(1,2,0).squeeze(),cmap = 'gray')

    elif pred_image != None :

        f, (ax1, ax2,ax3) = plt.subplots(1, 3, figsize=(10,5))

        ax1.set_title('IMAGE')
        ax1.imshow(image.permute(1,2,0).squeeze(),cmap = 'gray')

        ax2.set_title('GROUND TRUTH')
        ax2.imshow(mask.permute(1,2,0).squeeze(),cmap = 'gray')

        ax3.set_title('MODEL OUTPUT')
        ax3.imshow(pred_image.permute(1,2,0).squeeze(),cmap = 'gray')

show_image(image,mask)

"""## Load dataset into batches"""

from torch.utils.data import DataLoader
train_loader = DataLoader(trainset,batch_size = batch_size,shuffle = True)
valid_loader = DataLoader(validset,batch_size = batch_size,shuffle = True)

print(f'Total number of batches:',len(train_loader))
print(f'Total number of batches:',len(valid_loader))

for image,mask in train_loader:
  break

print(f'One batch image and shape:', image.shape)
print(f'One batch mask and shape:', mask.shape)

"""## Create Segmentation Model"""

from torch import nn
import segmentation_models_pytorch as smp
from segmentation_models_pytorch.losses import DiceLoss

class SegmentationModel(nn.Module):

  def __init__(self):
    super(SegmentationModel,self).__init__()

    self.arc = smp.Unet(
        encoder_name = encoder,
        encoder_weights = weights,
        in_channels = 3,
        classes = 1,
        activation = None
    )


  def forward(self,images,masks = None):
    logits = self.arc(images)

    if masks != None:
      loss1 = DiceLoss(mode = 'binary')(logits,masks)
      loss2 = nn.BCEWithLogitsLoss()(logits,masks)

      return logits,loss1+loss2

    return logits

model = SegmentationModel()
model.to(DEVICE)

"""## Create Train and Validation Functions"""

def train_fn(data_loader,model,optimizer):
  model.train()
  total_loss = 0.0

  for images,masks in tqdm(data_loader):
    images = images.to(DEVICE)
    masks = masks.to(DEVICE)
    optimizer.zero_grad()
    logits,loss = model(images,masks)
    loss.backward()
    optimizer.step()
    total_loss += loss.item()

  return total_loss/len(data_loader)

def eval_fn(data_loader,model,optimizer):
  model.eval()
  total_loss = 0.0

  with torch.no_grad():
    for images,masks in tqdm(data_loader):
      images = images.to(DEVICE)
      masks = masks.to(DEVICE)
      logits,loss = model(images,masks)
      total_loss += loss.item()
  return total_loss/len(data_loader)

"""## Train the Model"""

optimizer = torch.optim.Adam(model.parameters(),lr = LR)

best_valid_loss = np.inf

for i in range(epochs):
  train_loss = train_fn(train_loader,model,optimizer)
  val_loss= eval_fn(valid_loader,model,optimizer)

if val_loss < best_valid_loss:
  torch.save(model.state_dict(),'best_model.pt')
  print('Saved model')
  best_valid_loss = val_loss

print(f"Epoch : {i+1} Train_loss :{train_loss} Valid_loss :{val_loss}")

"""## Inference"""

idx = 42
model.load_state_dict(torch.load('/content/best_model.pt'))

image,mask = validset[idx]
logits_mask = model(image.to(DEVICE).unsqueeze(0))
pred_mask = torch.sigmoid(logits_mask)
pred_mask = (pred_mask>0.5)*1.0

show_image(image,mask,pred_mask.detach().cpu().squeeze(0))

